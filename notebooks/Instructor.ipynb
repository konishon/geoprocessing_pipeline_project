{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6db9aaa-f5c1-42f4-ba5a-34fc1802b702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "notebook_dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "project_root = os.path.abspath(os.path.join(notebook_dir, '..'))\n",
    "sys.path.append(project_root)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79bfc30-83ee-4a73-b9e7-62e2c65c3cfb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 1. Sample Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ca0c69-692b-480c-89b8-9956f70810bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "import instructor\n",
    "\n",
    "\n",
    "class UserDetail(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "\n",
    "\n",
    "# enables `response_model` in create call\n",
    "client = instructor.patch(\n",
    "    OpenAI(\n",
    "        base_url=\"http://localhost:11434/v1\",\n",
    "        api_key=\"ollama\",  # required, but unused\n",
    "    ),\n",
    "    mode=instructor.Mode.JSON,\n",
    ")\n",
    "\n",
    "user = client.chat.completions.create(\n",
    "    model=\"codegemma\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Jason is 30 years old\",\n",
    "        }\n",
    "    ],\n",
    "    response_model=UserDetail,\n",
    ")\n",
    "\n",
    "print(user)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036b95d6-6ea0-4407-9a75-0fd8fc17e68b",
   "metadata": {},
   "source": [
    "# 2. Using GeoProcessing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c08112c-fd9e-4a8d-9f3b-9231e5d28d10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "import instructor\n",
    "\n",
    "# Patch the OpenAI client with instructor\n",
    "client = instructor.patch(\n",
    "    OpenAI(\n",
    "        base_url=\"http://localhost:11434/v1\",\n",
    "        api_key=\"ollama\",  # required, but unused\n",
    "    ),\n",
    "    mode=instructor.Mode.JSON,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bb9703-d8a7-489c-9c26-06af3ba94953",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geoprocessing_pipeline.models import GeoprocessingPipeline\n",
    "\n",
    "# Define the function with the time calculation\n",
    "def run_geo_processing_pipeline():\n",
    "    # Record start time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    geo = client.chat.completions.create(\n",
    "        model=\"codellama\",\n",
    "        messages=[\n",
    "            {\n",
    "              \"role\": \"system\",\n",
    "              \"content\": \"\"\"You are a GIS expert assistant. Here are the available GIS features you can use in this session:\n",
    "      - **loadOsmData**: Load OpenStreetMap data for a specified geographical location.\n",
    "        - Input: address (e.g., 'Kathmandu, Nepal'), filepath (always stored in 'data/').\n",
    "      - **generateIsochrone**: Create an isochrone analysis for a given distance or time from a central point.\n",
    "        - Input: distance (in meters) or time (in minutes) to generate a travel buffer around a point.\n",
    "      - **filterPoints**: Apply attribute-based filtering on points, such as height, population, or other attributes.\n",
    "        - Input: attribute, operator (e.g., '>', '<', '='), value.\n",
    "      - **checkPointsWithinIsochrone**: Identify which points fall within a given isochrone buffer.\n",
    "      - **loadData**: Load geospatial data of a specified type (e.g., points, polygons, roads).\n",
    "        - Input: dataType (e.g., 'points', 'roads', 'buildings')\n",
    " \n",
    "        \"\"\"\n",
    "            },\n",
    "            {\n",
    "              \"role\":\"system\",\n",
    "                \"content\":\"You need to create the steps, to process the query and take output of one function as input of another function. Always process the user request using only the required set of necessary functions.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Find points where i can reach in 20 minutes from kathmandu nepal\",\n",
    "            }\n",
    "        ],\n",
    "        response_model=GeoprocessingPipeline,\n",
    "    )\n",
    "\n",
    "    # Record end time\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Calculate the duration and print the running time\n",
    "    duration = end_time - start_time\n",
    "    print(f\"Processing completed in {duration:.2f} seconds.\")\n",
    "    return geo\n",
    "\n",
    "\n",
    "geo = run_geo_processing_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c1b0ed-3f6c-447f-b084-9767a31fdb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(geo, depth=2,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048dc96a-4ba1-41c7-be5c-c8856a76f92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = json.dumps(geo, default=lambda o: o.dict())\n",
    "pprint(json_data, depth=1,indent=1)\n",
    "print(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16166098-9ada-4b5a-a06f-476dddc45d25",
   "metadata": {},
   "source": [
    "# 2. Running the logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72d31b9-f174-48de-84e3-e17a4556c7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from geoprocessing_pipeline.data_loader import load_or_download_graph, load_data_by_type\n",
    "from geoprocessing_pipeline.isochrone import generate_isochrone\n",
    "from geoprocessing_pipeline.filter import filter_points_by_complex_query, filter_points_within_isochrone\n",
    "from geoprocessing_pipeline.models import GeoprocessingPipeline, OsmDataInput\n",
    "from pydantic import ValidationError\n",
    "\n",
    "def run_geoprocessing_pipeline(json_data):\n",
    "    \"\"\"\n",
    "    Runs the geoprocessing pipeline based on a JSON configuration.\n",
    "\n",
    "    Parameters:\n",
    "    - json_data (dict or str): A dictionary or JSON string representing the JSON configuration for the pipeline.\n",
    "\n",
    "    Returns:\n",
    "    - dict: A dictionary containing the outputs of the various pipeline steps.\n",
    "    \"\"\"\n",
    "    # If json_data is a string, parse it into a dictionary\n",
    "    if isinstance(json_data, str):\n",
    "        try:\n",
    "            json_data = json.loads(json_data)\n",
    "        except json.JSONDecodeError as e:\n",
    "            raise ValueError(f\"Invalid JSON string: {e}\")\n",
    "\n",
    "    # This dictionary will hold the output of each function in the pipeline\n",
    "    outputs = {}\n",
    "\n",
    "    # Validate and parse the JSON configuration using the pydantic model\n",
    "    try:\n",
    "        pipeline = GeoprocessingPipeline(**json_data)\n",
    "    except ValidationError as e:\n",
    "        raise ValueError(f\"Invalid pipeline configuration: {e}\")\n",
    "\n",
    "    # Iterate through each function step in the pipeline configuration\n",
    "    for func in pipeline.functions:\n",
    "        func_name = func.functionName\n",
    "\n",
    "        # Load or download OSM data\n",
    "        if func_name == \"loadOsmData\":\n",
    "            # Check if input data is a reference (string) or a full OsmDataInput object\n",
    "            if isinstance(func.input.data, str):\n",
    "                # If it's a reference, retrieve the actual data from the outputs dictionary\n",
    "                osm_data_input = outputs[func.input.data]\n",
    "            else:\n",
    "                # Otherwise, it's a direct OsmDataInput object\n",
    "                osm_data_input = func.input.data\n",
    "\n",
    "            address = osm_data_input\n",
    "            filepath = osm_data_input.filepath\n",
    "            output = load_or_download_graph(address, filepath)\n",
    "        \n",
    "        # Generate Isochrone\n",
    "        elif func_name == \"generateIsochrone\":\n",
    "            # Retrieve the OSM network from the outputs (data is a reference key here)\n",
    "            osm_network = outputs[func.input.data]\n",
    "            distance = func.input.parameters.distance\n",
    "            output = generate_isochrone(osm_network, distance)\n",
    "        \n",
    "        # Load generic data (points, buildings, etc.)\n",
    "        elif func_name == \"loadData\":\n",
    "            data_type = func.input.parameters.dataType\n",
    "            output = load_data_by_type(data_type)\n",
    "        \n",
    "        # Filter Points by Complex Query (e.g., height > 20)\n",
    "        elif func_name == \"filterPoints\" and isinstance(func.input.parameters, FilterCriteria):\n",
    "            points = outputs[func.input.data]  # Use the points that were loaded earlier\n",
    "            attribute = func.input.parameters.attribute\n",
    "            operator = func.input.parameters.operator\n",
    "            value = func.input.parameters.value\n",
    "            output = filter_points_by_complex_query(points, attribute, operator, value)\n",
    "        \n",
    "        # Check which points are within the isochrone\n",
    "        elif func_name == \"checkPointsWithinIsochrone\":\n",
    "            points = outputs[func.input.data]\n",
    "            isochrone_polygon = outputs[func.input.parameters.isochrone]\n",
    "            output = filter_points_within_isochrone(points, isochrone_polygon)\n",
    "\n",
    "        # Store the output of this function in the outputs dictionary\n",
    "        outputs[func.output] = output\n",
    "\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c144ce-a0b7-462c-a530-38915dfdffb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data_input = json.loads(json_data)\n",
    "outputs = run_geoprocessing_pipeline(json_data_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5af0654-c6df-4aae-8086-7a66e902ef47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d340ec-cc87-4d7f-9dca-6afe2ff2eb89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ebb641-3b6b-440d-86cc-e107a1c371b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GeoPro Pipeline(.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
